"""
 Copyright (C) <year(s)> Intel Corporation

 SPDX-License-Identifier: Apache-2.0

"""
import os
import unittest

import configparser
from src.predictor.smoothed_ngram_predictor import SmoothedNgramPredictor
import src.predictor.utilities
from src.predictor.utilities.prediction import Prediction
import src.utilities.context_tracker 
import src.utilities.callback
from src.utilities.predictor_registry import PredictorRegistry
from src.utilities.suggestion import Suggestion


class TestSuggestion(unittest.TestCase):
    def setUp(self):
        self.my_suggestion = Suggestion("Test", 0.3, "test_predictor")

    def test_probability(self):
        self.my_suggestion.probability = 0.1
        assert self.my_suggestion.probability == 0.1


class TestPrediction(unittest.TestCase):
    def setUp(self):
        self.prediction = Prediction()

    def test_add_suggestion(self):
        self.prediction.add_suggestion(Suggestion("Test", 0.3, "test_predictor"))
        assert self.prediction[0].word == "Test"
        assert self.prediction[0].probability == 0.3

        self.prediction.add_suggestion(Suggestion("Test2", 0.2, "test_predictor"))
        assert self.prediction[0].word == "Test"
        assert self.prediction[0].probability == 0.3
        assert self.prediction[1].word == "Test2"
        assert self.prediction[1].probability == 0.2

        self.prediction.add_suggestion(Suggestion("Test3", 0.6, "test_predictor"))
        assert self.prediction[0].word == "Test3"
        assert self.prediction[0].probability == 0.6
        assert self.prediction[1].word == "Test"
        assert self.prediction[1].probability == 0.3
        assert self.prediction[2].word == "Test2"
        assert self.prediction[2].probability == 0.2

        self.prediction[:] = []

    def test_suggestion_for_token(self):
        self.prediction.add_suggestion(Suggestion("Token", 0.8, "test_predictor"))
        assert self.prediction.suggestion_for_token("Token").probability == 0.8
        self.prediction[:] = []


class StringStreamCallback(src.utilities.callback.Callback):
    def __init__(self, stream):
        src.utilities.callback.Callback.__init__(self)
        self.stream = stream


class TestSmoothedNgramPredictor(unittest.TestCase):
    def setUp(self):
        
        self.prediction = SmoothedNgramPredictor()
        
   
        
        
        self.dbfilename = os.path.abspath(
            os.path.join(os.path.dirname(__file__), "test_data", "test.db")
        )
        self.infile = os.path.abspath(
            os.path.join(os.path.dirname(__file__), "test_data", "der_linksdenker.txt")
        )

        for ngram_size in range(3):
            ngram_map = src.tokenizer.tokenizer.forward_tokenize_file(
                self.infile, ngram_size + 1, False
            )
            src.utilities.dbconnector.insert_ngram_map_sqlite(
                ngram_map, ngram_size + 1, self.dbfilename, False
            )

        config_file = os.path.abspath(
            os.path.join(
                os.path.dirname(__file__), "test_data", "profile_smoothedngram.ini"
            )
        )
        config = configparser.ConfigParser()
        config.read(config_file)
        config.set("Database", "database", self.dbfilename)

        self.predictor_registry = PredictorRegistry(config)

        self.callback = StringStreamCallback("")
        context_tracker = src.utilities.context_tracker.ContextTracker(
            config, self.predictor_registry, self.callback
        )

    def test_predict(self):
        predictor = self.predictor_registry[0]
        predictions = predictor.predict(6, None)
        assert len(predictions) == 6
        words = []
        for p in predictions:
            words.append(p.word)
        assert "er" in words
        assert "der" in words
        assert "die" in words
        assert "und" in words
        assert "nicht" in words

        self.callback.stream = "d"
        predictions = predictor.predict(6, None)
        assert len(predictions) == 6
        words = []
        for p in predictions:
            words.append(p.word)
        assert "der" in words
        assert "die" in words
        assert "das" in words
        assert "da" in words
        assert "Der" in words

        self.callback.stream = "de"
        predictions = predictor.predict(6, None)
        assert len(predictions) == 6
        words = []
        for p in predictions:
            words.append(p.word)
        assert "der" in words
        assert "Der" in words
        assert "dem" in words
        assert "den" in words
        assert "des" in words

    def tearDown(self):
        if self.predictor_registry[0].db:
            self.predictor_registry[0].db.close_database()
        del self.predictor_registry[0]
        if os.path.isfile(self.dbfilename):
            os.remove(self.dbfilename)
